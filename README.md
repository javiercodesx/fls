# Explicaci√≥n del Flujo Completo: `pnpx tsx src/reports/ososs/index.ts ai s3`

Este documento explica detalladamente qu√© sucede cuando se ejecuta el comando `pnpx tsx src/reports/ososs/index.ts ai s3`, desde el an√°lisis inicial hasta la subida a S3.

---

## üìã Tabla de Contenidos

1. [Inicio y Detecci√≥n de Argumentos](#1-inicio-y-detecci√≥n-de-argumentos)
2. [An√°lisis Inicial de URLs](#2-an√°lisis-inicial-de-urls)
3. [Procesamiento con IA (si est√° habilitado)](#3-procesamiento-con-ia-si-est√°-habilitado)
4. [Mapeo de Nombres](#4-mapeo-de-nombres)
5. [Procesamiento por Etapas con OpenAI](#5-procesamiento-por-etapas-con-openai)
6. [Guardado de Resultados de IA](#6-guardado-de-resultados-de-ia)
7. [Re-an√°lisis con Datos Enriquecidos](#7-re-an√°lisis-con-datos-enriquecidos)
8. [Generaci√≥n de Reportes CSV](#8-generaci√≥n-de-reportes-csv)
9. [Compresi√≥n en ZIP](#9-compresi√≥n-en-zip)
10. [Subida a S3 (si est√° habilitado)](#10-subida-a-s3-si-est√°-habilitado)

---

## 1. Inicio y Detecci√≥n de Argumentos

**Archivo:** `src/reports/ososs/index.ts`

Cuando se ejecuta el comando, el script comienza leyendo las URLs desde el archivo de entrada:

```typescript
const urls: string[] = readFileLinesSorted(`${import.meta.dirname}/in`);
```

Luego, se llama a `processAnalysis` desde `config.ts`:

```typescript
const analysisResult: AnalysisResult = await processAnalysis(urls, config, 'ososs');
```

**Archivo:** `src/reports/config.ts`

En `config.ts`, se detectan los argumentos del comando:

```typescript
const hasArgument: (pattern: RegExp) => boolean = (pattern: RegExp): boolean =>
  pattern.test(process.argv.slice(2).join(' '));

const shouldUseAI: () => boolean = (): boolean => hasArgument(/\b(?:openai|ai)\b/iv);
const shouldUploadToS3: () => boolean = (): boolean => hasArgument(/\bs3\b/iv);
```

- `process.argv.slice(2)` obtiene los argumentos: `['ai', 's3']`
- `shouldUseAI()` detecta "ai" o "openai" ‚Üí **true**
- `shouldUploadToS3()` detecta "s3" ‚Üí **true**

---

## 2. An√°lisis Inicial de URLs

**Archivo:** `src/reports/config.ts` ‚Üí `processAnalysis()`

```typescript
let analysisResult: AnalysisResult = await analyzeUrls(urls, config);
```

**Archivo:** `src/analyses/index.ts` ‚Üí `analyzeUrls()`

Este proceso realiza:

1. **Parseo de URLs:**
   - Lee las URLs desde el archivo `src/reports/ososs/in`
   - Usa `Getter` para obtener las recetas (desde cache o web)
   - Parsea cada URL y extrae la informaci√≥n de las recetas

2. **Ejecuci√≥n de Scorers:**
   - `runAllScorers()` ejecuta todos los scorers en diferentes etapas (stages)
   - Cada scorer analiza las recetas y genera:
     - **Resultados:** Metadatos y scores para cada receta
     - **Missing:** Datos faltantes que no se pudieron encontrar

3. **Estructura de Missing:**
   ```typescript
   AnyMissing = Map<string, Map<string, unknown[]>>
   // Ejemplo:
   // {
   //   "recipe-id-1": {
   //     "drug--diagnosis": [{drug: "alprazolam", icd10: "I61"}, ...],
   //     "drug--specialty": [{drug: "alprazolam", specialty: "medicina"}, ...],
   //     ...
   //   },
   //   ...
   // }
   ```

4. **Extracci√≥n de Datos:**
   - Extrae datos agregados por paciente, farmacia y m√©dico
   - Retorna `AnalysisResult` con:
     - `missing`: Todos los datos faltantes
     - `missingUrls`: URLs que no se pudieron parsear
     - `recipes`: Todas las recetas parseadas
     - `results`: Metadatos agregados

---

## 3. Procesamiento con IA (si est√° habilitado)

**Archivo:** `src/reports/config.ts` ‚Üí `processAnalysis()`

Como `shouldUseAI()` retorna `true`, se ejecuta:

```typescript
if (shouldUseAI()) {
  analysisResult = await processMissingWithAI(analysisResult, clientName, urls, config);
}
```

### 3.1. Guardado Temporal de Missing

**Archivo:** `src/reports/config.ts` ‚Üí `processMissingWithAI()`

```typescript
const tempMissingDir: string = `${import.meta.dirname}/${clientName}/out/.temp-missing-${getISOTimestamp()}`;
mkdirSync(`${tempMissingDir}/missing`, { recursive: true });
writeMissingReport(`${tempMissingDir}/missing`, analysisResult.missing);
```

- Crea un directorio temporal: `src/reports/ososs/out/.temp-missing-20251110005613/`
- `writeMissingReport()` genera archivos CSV por cada tipo de missing:
  - `drugDiagnosis.csv` (64 entradas)
  - `drugSpecialty.csv` (16 entradas)
  - `diagnosisSpecialty.csv` (35 entradas)
  - Y otros tipos que no tienen configuraci√≥n de IA

**Archivo:** `src/reports/generic/missing/index.ts`

Cada archivo CSV contiene las combinaciones √∫nicas de datos faltantes. Por ejemplo, `drugDiagnosis.csv`:
```csv
"drug";"icd10"
"alprazolam";"I61"
"alprazolam";"I63"
"atorvastatin";"E10"
...
```

---

## 4. Mapeo de Nombres

**Archivo:** `src/reports/config.ts`

Hay tres convenciones de nombres diferentes que necesitan mapearse:

### 4.1. Scorer Name (`drug--diagnosis`)
- Nombre interno usado por los scorers
- Definido en: `src/analyses/recipes/drug-diagnosis/index.ts`
- Usado en: `AnyMissing` para identificar qu√© scorer gener√≥ cada missing

### 4.2. Feedback Name (`drugDiagnosis`)
- Nombre de archivo CSV generado por `writeMissingReport`
- Nombre de carpeta en `src/feedback/data/` donde est√°n los prompts
- Usado por `processAllStages` para leer archivos y buscar configuraciones

### 4.3. Scorer Path (`drug-diagnosis`)
- Nombre de carpeta f√≠sica donde est√° el scorer
- Ruta: `src/analyses/recipes/drug-diagnosis/`
- Donde se guardan los archivos `missing/` generados por la IA

**Mapeos:**
```typescript
const scorerNameToFeedbackName: Map<string, string> = new Map([
  ['drug--diagnosis', 'drugDiagnosis'],
  ['drug--specialty', 'drugSpecialty'],
  ['diagnosis--specialty', 'diagnosisSpecialty'],
]);

const scorerNameToScorerPath: Map<string, string> = new Map([
  ['drug--diagnosis', 'drug-diagnosis'],
  ['drug--specialty', 'drug-specialty'],
  ['diagnosis--specialty', 'diagnosis-specialty'],
]);
```

---

## 5. Procesamiento por Etapas con OpenAI

**Archivo:** `src/reports/config.ts` ‚Üí `processMissingWithAI()`

```typescript
const aiResults: Record<string, Record<string, string>[]> = await processAllStages(
  new OpenAI({ apiKey: getEnv('OPENAI_API_KEY') }),
  tempMissingDir,
  1000,
);
```

**Archivo:** `src/feedback/index.ts` ‚Üí `processAllStages()`

### 5.1. Etapa Inicial (`initialStage`)

Lee todos los archivos CSV del directorio temporal y busca configuraciones:

```typescript
const initialStage = (reportDirectory) => {
  // Lee: reportDirectory/missing/*.csv
  // Para cada archivo (ej: drugDiagnosis.csv):
  //   1. Busca config en: src/feedback/data/drugDiagnosis/config.json
  //   2. Si existe, lee el CSV y lo convierte a formato interno
  //   3. Retorna: { drugDiagnosis: {...}, drugSpecialty: {...}, ... }
}
```

Solo procesa los tipos que tienen configuraci√≥n en `src/feedback/data/`.

### 5.2. Procesamiento por Etapas (`processStage`)

Itera por etapas (stage 0, 1, 2, ...) hasta que no haya m√°s etapas:

```typescript
for (let stage = 0; !done; stage++) {
  result = await processStage(openAi, stage, result, sleepMs, witness);
}
```

**Para cada tipo de missing (ej: `drugDiagnosis`):**

1. **Logging inicial:**
   ```
   Processing drugDiagnosis (stage 0) with 64 entries...
   ```

2. **Carga de configuraci√≥n:**
   - Lee `src/feedback/data/drugDiagnosis/config.json`:
     ```json
     {
       "chunkSize": 10,
       "keySeparator": "|",
       "resultKeys": ["drug", "icd10", "score"]
     }
     ```
   - Lee prompts:
     - `src/feedback/data/drugDiagnosis/0.system.txt`
     - `src/feedback/data/drugDiagnosis/0.user.txt`

3. **Divisi√≥n en chunks:**
   - Divide las 64 entradas en chunks de 10 (chunkSize)
   - Genera 7 chunks: `[chunk1, chunk2, ..., chunk7]`

4. **Procesamiento de cada chunk:**
   ```
   Processing chunk 1/7 for drugDiagnosis...
   ```
   
   - Interpola el prompt con los datos del chunk
   - Env√≠a a OpenAI (modelo: `gpt-4o-mini`, temperatura: 0.0)
   - Recibe JSON con resultados:
     ```json
     {
       "alprazolam|I61": "0",
       "alprazolam|I63": "1",
       ...
     }
     ```
   - Valida y parsea la respuesta
   
   ```
   Chunk 1/7 for drugDiagnosis complete
   ```
   
   - Espera 1000ms antes del siguiente chunk (rate limiting)

5. **Siguiente etapa (si existe):**
   - Si hay `1.system.txt` y `1.user.txt`, repite el proceso con los resultados de la etapa anterior
   - Contin√∫a hasta que no haya m√°s etapas

### 5.3. Formato Final

Al final, `processAllStages` convierte los resultados a arrays de objetos:

```typescript
{
  drugDiagnosis: [
    { drug: "alprazolam", icd10: "I61", score: "0" },
    { drug: "alprazolam", icd10: "I63", score: "1" },
    ...
  ],
  drugSpecialty: [...],
  diagnosisSpecialty: [...]
}
```

---

## 6. Guardado de Resultados de IA

**Archivo:** `src/reports/config.ts` ‚Üí `processMissingWithAI()`

Despu√©s de obtener los resultados de la IA, se guardan en las carpetas `missing/` de cada scorer:

```typescript
for (const [scorerName, feedbackName] of scorerNameToFeedbackName.entries()) {
  // scorerName = 'drug--diagnosis'
  // feedbackName = 'drugDiagnosis'
  
  const scorerPath = scorerNameToScorerPath.get(scorerName);
  // scorerPath = 'drug-diagnosis'
  
  const aiResult = aiResults[feedbackName];
  // aiResults['drugDiagnosis'] = [{drug: "...", icd10: "...", score: "..."}, ...]
  
  if (defined(scorerPath) && defined(aiResult) && 0 < aiResult.length) {
    const scorerMissingDir = `${import.meta.dirname}/../analyses/recipes/${scorerPath}/missing`;
    // = src/analyses/recipes/drug-diagnosis/missing
    
    // Convierte array de objetos a CSV
    const headers = Object.keys(aiResult[0]);
    const rows = aiResult.map(record => headers.map(header => record[header]));
    
    // Guarda el archivo
    writeRaw(`${scorerMissingDir}/${getISOTimestamp()}.csv`, rows, headers);
    // = src/analyses/recipes/drug-diagnosis/missing/20251110005613.csv
  }
}
```

**Archivos generados:**
- `src/analyses/recipes/drug-diagnosis/missing/20251110005613.csv`
- `src/analyses/recipes/drug-specialty/missing/20251110005613.csv`
- `src/analyses/recipes/diagnosis-specialty/missing/20251110005613.csv`

---

## 7. Re-an√°lisis con Datos Enriquecidos

**Archivo:** `src/reports/config.ts` ‚Üí `processMissingWithAI()`

```typescript
// Re-run analysis with enriched data
return await analyzeUrls(urls, config);
```

Se ejecuta `analyzeUrls` nuevamente, pero esta vez:

### 7.1. Scorers Modificados

Los scorers fueron modificados para leer archivos `missing/` en tiempo de ejecuci√≥n:

**Archivo:** `src/analyses/recipes/drug-diagnosis/index.ts`

```typescript
const loadDrugToIcd10 = () => {
  // Lee TODOS los archivos de src/analyses/recipes/drug-diagnosis/missing/
  // Incluyendo el nuevo archivo generado por la IA
  return new Map(...readFilesSorted(`${import.meta.dirname}/missing`)...);
};

const scorer = (recipes) => {
  // Se recarga cada vez que se ejecuta el scorer
  const drugToIcd10Runtime = loadDrugToIcd10();
  
  // Usa los datos enriquecidos para evaluar las recetas
  // Si encuentra una combinaci√≥n drug+icd10 en los archivos missing,
  // ya no la marca como "missing"
}
```

### 7.2. Resultado del Re-an√°lisis

El nuevo `AnalysisResult` tiene:
- **Menos missing:** Los datos generados por la IA ahora est√°n disponibles
- **M√°s resultados:** M√°s recetas tienen scores completos
- **Misma estructura:** Pero con datos m√°s completos

---

## 8. Generaci√≥n de Reportes CSV

**Archivo:** `src/reports/ososs/index.ts`

Con el `analysisResult` enriquecido, se generan todos los reportes CSV:

### 8.1. Reportes de Missing

```typescript
writeRaw(`${reportBaseDir}/missing/urls.csv`, ...);
writeRaw(`${reportBaseDir}/missing/diagnoses.csv`, ...);
writeMissingReport(`${reportBaseDir}/missing`, analysisResult.missing);
```

### 8.2. Reportes Principales

```typescript
writeRaw(`${reportBaseDir}/recipes.csv`, ...);
writeRaw(`${reportBaseDir}/billing.csv`, ...);
writeRaw(`${reportBaseDir}/stock.csv`, ...);
```

### 8.3. Reportes por Entidad

- **Pacientes:** `patientDrugs.csv`, `patientLaboratories.csv`, `patientProducts.csv`, `patientPharmacies.csv`, `patientTotals.csv`
- **M√©dicos:** `physicianDrugs.csv`, `physicianLaboratories.csv`, `physicianProducts.csv`, `physicianPharmacies.csv`, `physicianTotals.csv`
- **Farmacias:** `pharmacyDrugs.csv`, `pharmacyLaboratories.csv`, `pharmacyProducts.csv`, `pharmacyPharmacies.csv`, `pharmacyTotals.csv`

**Directorio generado:**
```
src/reports/ososs/out/20251110005617/
‚îú‚îÄ‚îÄ missing/
‚îÇ   ‚îú‚îÄ‚îÄ urls.csv
‚îÇ   ‚îú‚îÄ‚îÄ diagnoses.csv
‚îÇ   ‚îú‚îÄ‚îÄ drugDiagnosis.csv
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ recipes.csv
‚îú‚îÄ‚îÄ billing.csv
‚îú‚îÄ‚îÄ stock.csv
‚îú‚îÄ‚îÄ patientDrugs.csv
‚îî‚îÄ‚îÄ ... (17 archivos CSV en total)
```

---

## 9. Compresi√≥n en ZIP

**Archivo:** `src/reports/ososs/index.ts`

```typescript
await zip(
  reportBaseDir,
  `${import.meta.dirname}/out/ososs-${timestamp}.zip`,
  { compression: COMPRESSION_LEVEL.high }
);
```

- Comprime todo el directorio `20251110005617/` en un archivo ZIP
- Archivo generado: `src/reports/ososs/out/ososs-20251110005617.zip`

---

## 10. Subida a S3 (si est√° habilitado)

**Archivo:** `src/reports/ososs/index.ts`

Como `shouldUploadToS3()` retorna `true`, se ejecuta:

```typescript
if (shouldUploadToS3()) {
  await uploadReportToS3(reportBaseDir, 'ososs');
}
```

**Archivo:** `src/reports/config.ts` ‚Üí `uploadReportToS3()`

```typescript
const s3Client: S3Client = defaultS3Client();
const s3Prefix: string = getEnv('AWS_S3_BUCKET_NAME').replaceAll(/\/+$/gv, '');

await Promise.all([
  uploadToS3(
    s3Client,
    `${s3Prefix}/billing--ososs.csv`,
    readFileSync(`${reportBaseDir}/billing.csv`)
  ),
  uploadToS3(
    s3Client,
    `${s3Prefix}/recipes--ososs.csv`,
    readFileSync(`${reportBaseDir}/recipes.csv`)
  ),
]);
```

**Proceso:**
1. Crea cliente S3 con credenciales de las variables de entorno
2. Lee `billing.csv` y `recipes.csv` del directorio del reporte
3. Sube ambos archivos a S3 en paralelo:
   - `s3://bucket-name/billing--ososs.csv`
   - `s3://bucket-name/recipes--ososs.csv`

---

## üìä Resumen del Flujo Completo

```
1. Ejecuci√≥n: pnpx tsx src/reports/ososs/index.ts ai s3
   ‚Üì
2. Detecci√≥n de argumentos: ai=true, s3=true
   ‚Üì
3. An√°lisis inicial: analyzeUrls() ‚Üí identifica missing
   ‚Üì
4. Procesamiento con IA:
   ‚îú‚îÄ Guarda missing en directorio temporal
   ‚îú‚îÄ processAllStages() procesa con OpenAI
   ‚îú‚îÄ Guarda resultados en carpetas missing/ de scorers
   ‚îî‚îÄ Re-ejecuta analyzeUrls() con datos enriquecidos
   ‚Üì
5. Generaci√≥n de reportes CSV (17 archivos)
   ‚Üì
6. Compresi√≥n en ZIP
   ‚Üì
7. Subida a S3 (billing.csv y recipes.csv)
   ‚Üì
8. ‚úÖ Proceso completo
```

---

## üîë Puntos Clave

1. **Mapeo de nombres:** Conecta tres convenciones diferentes (scorer name, feedback name, scorer path)
2. **Lectura en tiempo de ejecuci√≥n:** Los scorers recargan archivos `missing/` cada vez que se ejecutan
3. **Procesamiento por etapas:** La IA puede procesar en m√∫ltiples etapas si hay configuraciones adicionales
4. **Chunking:** Los datos se dividen en chunks para evitar l√≠mites de tokens de OpenAI
5. **Rate limiting:** Espera 1 segundo entre chunks para evitar exceder l√≠mites de API
6. **Subida selectiva:** Solo se suben `billing.csv` y `recipes.csv` a S3, no todos los archivos

---

## üìù Notas Adicionales

- Si un scorer no tiene configuraci√≥n de IA, simplemente se omite del procesamiento
- Los errores de OpenAI se capturan y registran, pero no detienen el proceso completo

---

## üóÇÔ∏è Gesti√≥n de Archivos: Temporales y Acumulativos

### Archivos Temporales (`.temp-missing-*`)

**Ubicaci√≥n:** `src/reports/ososs/out/.temp-missing-20251110005613/`

**¬øQu√© son?**
Estos directorios se crean temporalmente para almacenar los missing antes de procesarlos con IA. Contienen los archivos CSV generados por `writeMissingReport()` que luego son le√≠dos por `processAllStages()`.

**¬øSe borran autom√°ticamente?**
**NO.** Actualmente el c√≥digo no elimina estos directorios despu√©s del procesamiento. Son "temporales" en el sentido de que:
- Solo se usan durante el procesamiento con IA
- No son parte del reporte final
- Se pueden eliminar manualmente sin afectar el funcionamiento

**¬øPor qu√© no se borran autom√°ticamente?**
- Permiten debugging: puedes revisar qu√© missing se enviaron a la IA
- Permiten re-procesamiento: si hay un error, puedes reutilizar los mismos datos
- No ocupan mucho espacio (solo CSVs de texto)

**Recomendaci√≥n:**
Si quieres limpiarlos autom√°ticamente, podr√≠as agregar al final de `processMissingWithAI()`:
```typescript
import { rmSync } from 'node:fs';
// ... despu√©s de guardar los resultados
rmSync(tempMissingDir, { recursive: true, force: true });
```

### Archivos en `missing/` de los Scorers

**Ubicaci√≥n:** `src/analyses/recipes/drug-diagnosis/missing/20251110005613.csv`

**¬øQu√© son?**
Estos son los archivos generados por la IA que contienen los datos enriquecidos. Se guardan en las carpetas `missing/` de cada scorer para que sean le√≠dos en futuros an√°lisis.

**¬øSe acumulan?**
**S√ç.** Cada vez que se ejecuta el procesamiento con IA, se crea un nuevo archivo con un timestamp √∫nico:
- `20251110005613.csv` (primera ejecuci√≥n)
- `20251110005704.csv` (segunda ejecuci√≥n)
- `20251110005815.csv` (tercera ejecuci√≥n)
- ...

**¬øPor qu√© se acumulan?**
1. **Historial:** Permite ver qu√© datos se generaron en cada ejecuci√≥n
2. **No sobrescribir:** Si un archivo tiene datos buenos, no se pierden con una nueva ejecuci√≥n
3. **Lectura acumulativa:** Los scorers leen TODOS los archivos en `missing/`, as√≠ que:
   - Datos antiguos + Datos nuevos = Base de conocimiento m√°s completa
   - Cada ejecuci√≥n agrega conocimiento sin perder el anterior

**¬øEst√° bien este funcionamiento?**
**S√ç, es el comportamiento deseado.** Razones:

1. **Base de conocimiento creciente:**
   ```
   Primera ejecuci√≥n: 10 combinaciones drug+icd10
   Segunda ejecuci√≥n: +5 nuevas combinaciones
   Tercera ejecuci√≥n: +3 nuevas combinaciones
   Total disponible: 18 combinaciones
   ```

2. **Los scorers leen todos los archivos:**
   ```typescript
   // En drug-diagnosis/index.ts
   ...readFilesSorted(`${import.meta.dirname}/missing`).map(...)
   // Lee TODOS los CSV en la carpeta missing/
   ```

3. **Ventajas:**
   - Cada ejecuci√≥n mejora la base de conocimiento
   - No se pierden datos validados anteriormente
   - Permite revisar el historial de generaciones

**Consideraciones:**
- Los archivos se acumulan indefinidamente
- Si hay muchos archivos, el tiempo de lectura puede aumentar ligeramente
- Si necesitas limpiar archivos antiguos, puedes hacerlo manualmente o agregar una l√≥gica de rotaci√≥n

**Ejemplo de acumulaci√≥n:**
```
src/analyses/recipes/drug-diagnosis/missing/
‚îú‚îÄ‚îÄ 20250721000000.csv  (archivo manual anterior)
‚îú‚îÄ‚îÄ 20250722152600.csv  (archivo manual anterior)
‚îú‚îÄ‚îÄ 20250918000000.csv  (archivo manual anterior)
‚îú‚îÄ‚îÄ 20251110005613.csv  (generado por IA - ejecuci√≥n 1)
‚îú‚îÄ‚îÄ 20251110005704.csv  (generado por IA - ejecuci√≥n 2)
‚îî‚îÄ‚îÄ 20251110005815.csv  (generado por IA - ejecuci√≥n 3)
```

Todos estos archivos se leen y se combinan cuando el scorer se ejecuta.

---

## üîÑ Cambio Cr√≠tico: Lectura de Archivos en Tiempo de Ejecuci√≥n vs Tiempo de Importaci√≥n

### El Problema Original

**¬øC√≥mo estaba antes?**

Antes del cambio, el c√≥digo le√≠a los archivos `missing/` **al importar el m√≥dulo**:

```typescript
// ‚ùå C√ìDIGO ANTERIOR (no funciona con IA)
const drugToIcd10: Map<string, Map<string, Category>> = new Map(
  Array.from(
    array_categorize([
      // ... datos del dataset base ...
      ...readFilesSorted(`${import.meta.dirname}/missing`).map(...)
    ])
  )
);

const scorer = (recipes) => {
  // Usa drugToIcd10 que ya fue inicializado al importar
  const icd10s = drugToIcd10.get(drug);
  // ...
}
```

**¬øQu√© es un "m√≥dulo" en JavaScript/TypeScript?**

Un m√≥dulo es un archivo `.ts` o `.js` que se importa usando `import`. Cuando Node.js/TypeScript ejecuta tu c√≥digo:

1. **Primera vez que se importa un m√≥dulo:**
   - Lee el archivo
   - Ejecuta TODO el c√≥digo de nivel superior (fuera de funciones)
   - Guarda el resultado en un cach√©
   - Retorna las exportaciones

2. **Siguientes veces que se importa:**
   - **NO vuelve a ejecutar el c√≥digo**
   - Retorna directamente desde el cach√©

**Ejemplo del problema:**

```typescript
// archivo: scorer.ts
console.log('M√≥dulo cargado'); // ‚Üê Solo se ejecuta UNA VEZ

const datos = readFileSync('datos.json'); // ‚Üê Solo se lee UNA VEZ

export const scorer = () => {
  return datos; // ‚Üê Siempre retorna los mismos datos
};
```

Si ejecutas:
```typescript
import { scorer } from './scorer.ts'; // ‚Üê Lee datos.json
// ... tiempo despu√©s ...
// Modificas datos.json
scorer(); // ‚Üê A√öN retorna los datos ANTIGUOS (del cach√©)
```

### El Problema en Nuestro Caso

**Flujo con el c√≥digo anterior:**

```
1. Se ejecuta: pnpx tsx src/reports/ososs/index.ts ai
   ‚Üì
2. Node.js importa src/reports/ososs/index.ts
   ‚Üì
3. index.ts importa src/analyses/index.ts
   ‚Üì
4. analyses/index.ts importa src/analyses/recipes/index.ts
   ‚Üì
5. recipes/index.ts importa src/analyses/recipes/drug-diagnosis/index.ts
   ‚Üì
6. ‚ö†Ô∏è AQU√ç SE EJECUTA EL C√ìDIGO DE NIVEL SUPERIOR:
   const drugToIcd10 = new Map(...readFilesSorted('missing')...);
   // Lee: missing/20250721000000.csv
   // Lee: missing/20250918000000.csv
   // NO hay archivos nuevos a√∫n
   // drugToIcd10 se inicializa con solo estos 2 archivos
   ‚Üì
7. Se ejecuta analyzeUrls() ‚Üí identifica missing
   ‚Üì
8. Se procesa con IA ‚Üí genera missing/20251110005613.csv
   ‚Üì
9. Se ejecuta analyzeUrls() NUEVAMENTE
   ‚Üì
10. ‚ö†Ô∏è PROBLEMA: El m√≥dulo YA EST√Å CARGADO
    // Node.js NO vuelve a ejecutar el c√≥digo de nivel superior
    // drugToIcd10 sigue teniendo solo los 2 archivos antiguos
    // El nuevo archivo 20251110005613.csv NO se lee
    ‚Üì
11. Resultado: Los missing NO se reducen
```

**Visualizaci√≥n del problema:**

```
Tiempo de importaci√≥n (una sola vez):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ import drug-diagnosis/index.ts      ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Ejecuta:                             ‚îÇ
‚îÇ   readFilesSorted('missing')        ‚îÇ
‚îÇ   ‚Üí [20250721000000.csv,            ‚îÇ
‚îÇ      20250918000000.csv]            ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Inicializa: drugToIcd10             ‚îÇ
‚îÇ   (con solo 2 archivos)             ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Guarda en cach√© del m√≥dulo          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Tiempo de ejecuci√≥n (m√∫ltiples veces):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ analyzeUrls() ‚Üí scorer()             ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Usa: drugToIcd10 (del cach√©)        ‚îÇ
‚îÇ   (sigue teniendo solo 2 archivos)  ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ ‚ùå NO lee el nuevo archivo          ‚îÇ
‚îÇ   20251110005613.csv                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### La Soluci√≥n: Lectura en Tiempo de Ejecuci√≥n

**¬øC√≥mo est√° ahora?**

El c√≥digo ahora lee los archivos **cada vez que se ejecuta el scorer**:

```typescript
// ‚úÖ C√ìDIGO ACTUAL (funciona con IA)
const loadDrugToIcd10 = () => {
  // Esta funci√≥n se puede llamar m√∫ltiples veces
  return new Map(
    Array.from(
      array_categorize([
        // ... datos del dataset base ...
        ...readFilesSorted(`${import.meta.dirname}/missing`).map(...)
        // ‚Üë Se ejecuta CADA VEZ que se llama la funci√≥n
      ])
    )
  );
};

const scorer = (recipes) => {
  // ‚ö†Ô∏è IMPORTANTE: Se recarga cada vez que se ejecuta el scorer
  const drugToIcd10 = loadDrugToIcd10(); // ‚Üê Lee archivos AHORA
  // Usa drugToIcd10 que tiene TODOS los archivos (incluyendo nuevos)
}
```

**Flujo con el c√≥digo actual:**

```
1. Se ejecuta: pnpx tsx src/reports/ososs/index.ts ai
   ‚Üì
2. Node.js importa todos los m√≥dulos
   ‚Üì
3. ‚ö†Ô∏è loadDrugToIcd10() NO se ejecuta a√∫n
   (solo se define la funci√≥n)
   ‚Üì
4. Se ejecuta analyzeUrls() ‚Üí identifica missing
   ‚Üì
5. Se procesa con IA ‚Üí genera missing/20251110005613.csv
   ‚Üì
6. Se ejecuta analyzeUrls() NUEVAMENTE
   ‚Üì
7. ‚úÖ scorer() se ejecuta
   ‚Üì
8. ‚úÖ loadDrugToIcd10() se LLAMA (no estaba en cach√©)
   ‚Üì
9. ‚úÖ readFilesSorted('missing') se ejecuta AHORA
   // Lee: missing/20250721000000.csv
   // Lee: missing/20250918000000.csv
   // Lee: missing/20251110005613.csv ‚Üê NUEVO ARCHIVO
   ‚Üì
10. ‚úÖ drugToIcd10 se inicializa con TODOS los archivos
    ‚Üì
11. ‚úÖ Resultado: Los missing S√ç se reducen
```

**Visualizaci√≥n de la soluci√≥n:**

```
Tiempo de importaci√≥n (una sola vez):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ import drug-diagnosis/index.ts      ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Define: loadDrugToIcd10()           ‚îÇ
‚îÇ   (NO ejecuta, solo define)        ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Guarda funci√≥n en cach√©             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Tiempo de ejecuci√≥n (m√∫ltiples veces):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ analyzeUrls() ‚Üí scorer()             ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Ejecuta: loadDrugToIcd10()          ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Ejecuta: readFilesSorted('missing') ‚îÇ
‚îÇ   ‚Üí [20250721000000.csv,            ‚îÇ
‚îÇ      20250918000000.csv,            ‚îÇ
‚îÇ      20251110005613.csv] ‚Üê NUEVO   ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Inicializa: drugToIcd10           ‚îÇ
‚îÇ   (con TODOS los archivos)          ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ ‚úÖ Usa datos actualizados           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Comparaci√≥n Detallada

| Aspecto | C√≥digo Anterior ‚ùå | C√≥digo Actual ‚úÖ |
|---------|-------------------|------------------|
| **Cu√°ndo se lee** | Al importar el m√≥dulo (una vez) | Cada vez que se ejecuta el scorer |
| **Cach√© de m√≥dulo** | Los datos quedan en cach√© | La funci√≥n queda en cach√©, pero se ejecuta cada vez |
| **Nuevos archivos** | ‚ùå No se leen | ‚úÖ Se leen |
| **Re-an√°lisis** | ‚ùå Usa datos antiguos | ‚úÖ Usa datos actualizados |
| **Performance** | ‚ö° M√°s r√°pido (lee una vez) | üêå M√°s lento (lee cada vez) |
| **Funcionalidad con IA** | ‚ùå No funciona | ‚úÖ Funciona correctamente |

### ¬øPor Qu√© Este Cambio es Necesario?

**Raz√≥n 1: El Sistema de M√≥dulos de Node.js**

Node.js (y TypeScript compilado) usa un sistema de cach√© de m√≥dulos:
- Cada m√≥dulo se ejecuta **una sola vez** cuando se importa por primera vez
- El c√≥digo de nivel superior (fuera de funciones) se ejecuta **solo una vez**
- Las constantes y variables se inicializan **solo una vez**

**Raz√≥n 2: El Flujo con IA Requiere Re-lectura**

Nuestro flujo es:
1. An√°lisis inicial ‚Üí identifica missing
2. IA genera nuevos archivos `missing/`
3. Re-an√°lisis ‚Üí debe leer los nuevos archivos

Si los archivos se leen solo al importar, el paso 3 no puede ver los nuevos archivos.

**Raz√≥n 3: La Soluci√≥n Mantiene Compatibilidad**

La soluci√≥n actual:
- Mantiene la funci√≥n `loadDrugToIcd10()` disponible
- Se puede llamar m√∫ltiples veces
- Cada llamada lee los archivos frescos del disco
- No rompe c√≥digo existente

### Ejemplo Concreto del Problema

**Con c√≥digo anterior (no funciona):**

```typescript
// T=0: Se importa el m√≥dulo
const drugToIcd10 = new Map(...readFilesSorted('missing')...);
// Lee: [archivo1.csv, archivo2.csv]
// drugToIcd10 tiene 100 combinaciones

// T=1: Se ejecuta analyzeUrls() primera vez
scorer(recipes);
// Usa drugToIcd10 con 100 combinaciones
// Identifica 50 missing

// T=2: IA genera archivo3.csv con 30 nuevas combinaciones
// Guarda: missing/20251110005613.csv

// T=3: Se ejecuta analyzeUrls() segunda vez
scorer(recipes);
// ‚ö†Ô∏è PROBLEMA: drugToIcd10 sigue teniendo solo 100 combinaciones
// (no lee archivo3.csv porque el m√≥dulo ya est√° en cach√©)
// Identifica 50 missing (igual que antes) ‚ùå
```

**Con c√≥digo actual (funciona):**

```typescript
// T=0: Se importa el m√≥dulo
const loadDrugToIcd10 = () => { ... };
// Solo se define la funci√≥n, NO se ejecuta

// T=1: Se ejecuta analyzeUrls() primera vez
scorer(recipes);
  ‚Üí loadDrugToIcd10(); // Se ejecuta AHORA
  ‚Üí Lee: [archivo1.csv, archivo2.csv]
  ‚Üí drugToIcd10 tiene 100 combinaciones
// Identifica 50 missing

// T=2: IA genera archivo3.csv con 30 nuevas combinaciones
// Guarda: missing/20251110005613.csv

// T=3: Se ejecuta analyzeUrls() segunda vez
scorer(recipes);
  ‚Üí loadDrugToIcd10(); // Se ejecuta AHORA (nuevamente)
  ‚Üí Lee: [archivo1.csv, archivo2.csv, archivo3.csv] ‚Üê NUEVO
  ‚Üí drugToIcd10 tiene 130 combinaciones ‚úÖ
// Identifica 20 missing (reducci√≥n de 30) ‚úÖ
```

### Conclusi√≥n

El cambio de leer archivos **al importar** a leer archivos **en tiempo de ejecuci√≥n** es necesario porque:

1. **El sistema de m√≥dulos de Node.js cachea el c√≥digo** ejecutado al importar
2. **Los nuevos archivos generados por la IA** aparecen despu√©s de que el m√≥dulo ya fue importado
3. **El re-an√°lisis necesita leer los nuevos archivos** para reducir los missing
4. **La soluci√≥n permite re-lectura** cada vez que se ejecuta el scorer

Sin este cambio, el sistema de IA no funcionar√≠a porque los datos enriquecidos nunca se usar√≠an en el segundo an√°lisis.

